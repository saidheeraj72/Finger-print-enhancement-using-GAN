{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8262306,"sourceType":"datasetVersion","datasetId":4904155}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport cv2 as cv \nimport sklearn \nfrom matplotlib import pyplot as plt \nimport tensorflow as tf \nimport keras \nimport seaborn\nfrom IPython import display","metadata":{"execution":{"iopub.status.busy":"2024-04-30T07:43:14.608766Z","iopub.execute_input":"2024-04-30T07:43:14.609599Z","iopub.status.idle":"2024-04-30T07:43:14.615625Z","shell.execute_reply.started":"2024-04-30T07:43:14.609561Z","shell.execute_reply":"2024-04-30T07:43:14.614304Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def get_file_path(directory, filename):\n    return os.path.join(directory, filename)","metadata":{"execution":{"iopub.status.busy":"2024-04-30T07:43:14.617284Z","iopub.execute_input":"2024-04-30T07:43:14.617630Z","iopub.status.idle":"2024-04-30T07:43:14.627820Z","shell.execute_reply.started":"2024-04-30T07:43:14.617603Z","shell.execute_reply":"2024-04-30T07:43:14.626881Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def plot_images(images):\n    rows = 3\n    cols = 3\n    fig, axes = plt.subplots(rows, cols, figsize=(8, 8))\n    #plotting images\n    for i in range(rows):\n        for j in range(cols):\n            axes[i, j].imshow(images[i * cols + j], cmap='gray')\n            axes[i, j].axis('off')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-30T07:43:14.629804Z","iopub.execute_input":"2024-04-30T07:43:14.630120Z","iopub.status.idle":"2024-04-30T07:43:14.637938Z","shell.execute_reply.started":"2024-04-30T07:43:14.630086Z","shell.execute_reply":"2024-04-30T07:43:14.637032Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"# Preparing Train","metadata":{}},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-04-30T07:43:14.640576Z","iopub.execute_input":"2024-04-30T07:43:14.641278Z","iopub.status.idle":"2024-04-30T07:43:14.646728Z","shell.execute_reply.started":"2024-04-30T07:43:14.641236Z","shell.execute_reply":"2024-04-30T07:43:14.645773Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"train_path=r'/kaggle/input/finger-print-dataset/Dataset/train'\nfiles=os.listdir(train_path)\nprint('Train image data loading')\nTrain_data=[]\nfor file in files:\n    image_path=get_file_path(train_path,file)\n    img=cv.imread(image_path)\n    Train_data.append(img)\nprint(\"Data loading Completed\")\nTrain_data=np.array(Train_data)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-04-30T07:43:14.648788Z","iopub.execute_input":"2024-04-30T07:43:14.649062Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Train image data loading\n","output_type":"stream"}]},{"cell_type":"code","source":"#normalizing between[-1,1]\nTrain_data=Train_data/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(Train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"enhance_path=r'/kaggle/input/finger-print-dataset/Dataset/enhace_train'\nfiles=os.listdir(enhance_path)\nprint('Enhanced image data loading')\nE_Train_data=[]\nfor file in files:\n    image_path=get_file_path(enhance_path,file)\n    img=cv.imread(image_path)\n    img=cv.resize(img,(256,256))\n    E_Train_data.append(img)\nprint(\"Data loading Completed\")\nE_Train_data=np.array(E_Train_data)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nE_Train_data=E_Train_data/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(E_Train_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_data=Train_data[4:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"E_Train_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# APPLYING GAN","metadata":{}},{"cell_type":"code","source":"def generator_model():\n    \n     #generator model \n    input=tf.keras.layers.Input(shape=(512,512,3))\n    x=tf.keras.layers.Conv2D(128,(5,5),strides=(1,1),padding='same',activation='relu',use_bias=False)(input)\n    x=tf.keras.layers.Conv2D(128,(5,5),strides=(2,2),padding='same',activation='relu',use_bias=False)(x)\n    \n    x=tf.keras.layers.Conv2D(64,(5,5),strides=(1,1),padding='same',activation='relu',use_bias=False)(x)\n    x=tf.keras.layers.Conv2D(64,(5,5),strides=(2,2),padding='same',activation='relu',use_bias=False)(x)\n    \n    x=tf.keras.layers.Conv2D(32,(5,5),strides=(1,1),padding='same',activation='relu',use_bias=False)(x)\n    x=tf.keras.layers.Conv2D(32,(5,5),strides=(2,2),padding='same',activation='relu',use_bias=False)(x)\n    \n    x=tf.keras.layers.Conv2DTranspose(32,(5,5),strides=(1,1),padding='same',activation='relu')(x)\n    x=tf.keras.layers.Conv2DTranspose(32,(5,5),strides=(2,2),padding='same',activation='relu',use_bias=False)(x)\n    \n    x=tf.keras.layers.Conv2DTranspose(64,(5,5),strides=(1,1),padding='same',activation='relu')(x)\n    x=tf.keras.layers.Conv2DTranspose(64,(5,5),strides=(2,2),padding='same',activation='relu',use_bias=False)(x)\n    \n    output=tf.keras.layers.Conv2DTranspose(3,(5,5),strides=(1,1),padding='same',use_bias=False ,activation='sigmoid')(x)\n\n    return tf.keras.Model(inputs=input,outputs=output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator=generator_model() \ngenerator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#use for a single instance\nimg_batch = np.expand_dims(Train_data[0], axis=0)\ngenerated_image=generator(img_batch,training=False) \nplt.imshow(generated_image[0],cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_model():\n\n    input=tf.keras.layers.Input(shape=(256,256,3))\n    x=tf.keras.layers.Conv2D(32,(5,5),strides=(2,2),padding='same')(input)\n    x=tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n    x=tf.keras.layers.Dropout(0.3)(x)\n    \n    x=tf.keras.layers.Conv2D(64,(5,5),strides=(2,2),padding='same')(x)\n    x=tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n    x=tf.keras.layers.Dropout(0.3)(x)\n\n    x=tf.keras.layers.Conv2D(128,(5,5),strides=(2,2),padding='same')(x)\n    x=tf.keras.layers.LeakyReLU(alpha=0.1)(x)\n    x=tf.keras.layers.Dropout(0.3)(x)\n\n    x=tf.keras.layers.Flatten()(x)\n    output=tf.keras.layers.Dense(1,activation='sigmoid')(x)\n\n    return tf.keras.Model(inputs=input,outputs=output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator=discriminator_model()\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decision=discriminator(generated_image)\nprint(decision)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Custom Loss Functions","metadata":{}},{"cell_type":"markdown","source":"# Adversial Loss","metadata":{}},{"cell_type":"code","source":"cross_entropy=tf.keras.losses.BinaryCrossentropy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def discriminator_loss(real_output,fake_output):\n    real_loss=cross_entropy(tf.ones_like(real_output),real_output)\n    fake_loss=cross_entropy(tf.zeros_like(fake_output),fake_output)\n    total_loss=real_loss+fake_loss \n    return total_loss \n\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output),fake_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reconstruction Loss","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef reconstruction_loss(image1, image2):\n    mse_total = mse(image1, image2)\n    return mse_total / tf.cast(tf.shape(image1)[0], tf.float32)  # Divide by batch size\n\ndef mse(image1, image2):\n    image1 = tf.cast(image1, tf.float32)\n    image2 = tf.cast(image2, tf.float32)\n    # Cast image1 to float32\n    mse = tf.reduce_mean(tf.square(image1 - image2))\n    return mse\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Orientation Loss","metadata":{}},{"cell_type":"code","source":"def orientation_loss(image1,image2):\n    ori_total=0 \n    for i,j in zip(image1,image2):\n        ori_total+=orientation(i,j)\n    return ori_total/len(image1)\n    \n\ndef orientation(image1,image2):\n    detector = cv2.ORB_create()\n    keypoints1, descriptors1 = detector.detectAndCompute(image1, None)\n    keypoints2, descriptors2 = detector.detectAndCompute(image2, None)\n\n    # Match keypoints between the images\n    matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n    matches = matcher.match(descriptors1, descriptors2)\n\n    orientation_difference = 0\n    for match in matches:\n        kp1 = keypoints1[match.queryIdx]\n        kp2 = keypoints2[match.trainIdx]\n        orientation_difference += abs(kp1.angle - kp2.angle)\n\n    average_orientation_difference = orientation_difference / len(matches)\n    \n    return average_orientation_difference\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_optimezer=tf.keras.optimizers.Adam(1e-4)\ndisc_optimezer=tf.keras.optimizers.Adam(1e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function \n# causes the function to be compiled \ndef train_step(real_images,images,l1):\n\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images=generator(real_images,training=True)\n\n        real_output=discriminator(images,training=True)\n        fake_output=discriminator(generated_images,training=True)\n        \n#         gen_loss=generator_loss(fake_output)+(l1*reconstruction_loss(images, generated_images))+(l2*orientation_loss(images, generated_images))\n        gen_loss=generator_loss(fake_output)+(l1*reconstruction_loss(images, generated_images))\n        disc_loss=discriminator_loss(real_output,fake_output)\n        \n\n    gradients_of_generator=gen_tape.gradient(gen_loss,generator.trainable_variables)\n    gradients_of_discriminator=disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n\n    gen_optimezer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))\n    disc_optimezer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_and_save_images(model, epoch, test_input):\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(9, 9))\n\n  for i in range(predictions.shape[0]):\n      plt.subplot(3, 3, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 255, cmap='gray')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\ndef train(dataset, dataset2, epochs, batch_size,test):\n    num_batches = len(dataset) // batch_size\n    \n    for epoch in range(epochs):\n        print(\"Epoch {} started\".format(epoch + 1))\n        for batch_index in range(num_batches):\n            start_index = batch_index * batch_size\n            end_index = start_index + batch_size\n            image_batch = dataset[start_index:end_index]\n            enhanced_batch = dataset2[start_index:end_index]\n            train_step(image_batch, enhanced_batch,0.5)\n        \n        # Display generated images after each epoch\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epoch + 1, test)\n        \n        print(\"Epoch {} completed\".format(epoch + 1))\n    \n    # Display final generated images\n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epoch, test)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_images=tf.expand_dims(train_images,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path=r'/kaggle/input/finger-print-dataset/Dataset/test'\nfiles=os.listdir(test_path)\nprint('Test image data loading')\nTest_data=[]\nfor file in files:\n    image_path=get_file_path(test_path,file)\n    img=cv.imread(image_path)\n    Test_data.append(img)\nprint(\"Data loading Completed\")\nTest_data=np.array(Test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_images(Test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test_data=Test_data/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sample=Test_data[:9]\nEPOCHS=10\nbatch_size=10\ntrain(Train_data,E_Train_data,EPOCHS,batch_size,test_sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_path=r'/kaggle/working/image_at_epoch_0007.png'\n# display.clear_output(wait=True)\n# img=cv.imread(image_path)\n# plt.imshow(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}